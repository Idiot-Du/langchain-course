
目标检测、大模型领域的发展现状调研

目标检测作为计算机视觉领域的核心任务之一，已经取得了显著的进展。随着深度学习技术的发展，目标检测方法经历了从传统的区域提议方法到端到端的深度学习模型的变革。近年来，随着Transformer架构的崛起，目标检测领域也引入了这一新兴技术。Transformer的优势在于其出色的全局特征建模能力，使得基于Transformer的模型在目标检测中展现出良好的性能。
此外，随着开放词汇目标检测、多模态目标检测和小目标检测等研究方向的兴起，目标检测的研究内容日益丰富。多模态学习也被引入目标检测任务中，通过融合视觉、文本、语音等模态的信息，进一步提升了模型的鲁棒性和泛化能力，尤其在复杂环境下的应用表现更加突出。
目标检测与大语言模型（LLM）的结合也成为当前研究的热点。大语言模型在自然语言处理领域的成功应用，激发了其在跨模态学习中的潜力。例如，视觉问答、图像描述生成等任务结合了目标检测和语言模型的优势，推动了智能系统向多模态理解和推理的方向发展。本文深入探讨目标检测领域的国内外研究现状，并分析多模态学习、开放词汇检测以及小目标检测等前沿问题的最新进展，为未来的研究提供参考。
2 目标检测领域的国内外研究现状

目标检测是计算机视觉领域的核心任务。随着深度学习技术的发展，学者们先后提出了R-CNN、Faster R-CNN网络的二阶段算法用于解决目标检测任务，目标检测研究进入高速发展阶段。后又有学者提出一阶段算法，典型的一阶段算法例如YOLO方法、SSD方法，解决了二阶段算法检测精度高但速度慢的问题，具有较好的性能。近年来，许多研究者将Transformer引入计算机视觉领域，提出许多基于transformer的高性能视觉模型，典型的结构DERT直接将目标检测视为集合预测问题，消除了非最大抑制和锚生成过程，简化了检测任务。
最早期的R-CNN算法[ 4]采用选择性搜索(Selective Search,SS)算法来生成候选框。随后，将生成的候选框作为输入，通过卷积神经网络提取输入图像的特征，最后利用支持向量机的特性进行边界框回归及分类预测。然而，该算法存在耗时长、占用存储空间大、计算存在冗余等问题。
为了解决这些问题，R.Girshick等人提出了Fast R-CNN算法[ 5]，对R-CNN算法进行了改进。改进的主要思路包括将整张图片输入特征提取网络进行特征提取，利用选择性搜索生成的候选框映射到特征图上，引入感兴趣区域池化层(ROI pooling)，从而提高检测速度和精度。在同一年，Ren等人提出了Faster R-CNN算法[ 6]，用区域建议网络替换原有的选择性搜索算法来生成候选框，实现了端到端的训练，大大减少了训练时间，同时也有效地提高了检测精度和速度。
2016年，Redmon等人提出了YOLOv1(You Only Look Once)算法[ 7]，该算法将图像划分为7×7 大小的网格，并直接使用网格中的信息来进行边界框回归和类别预测，从而实现了端到端的目标检测。同时，该算法也采用了卷积神经网络进行特征提取，大大提高了检测的速度。然而，该算法存在着对小目标检测效果差、定位精度不高等问题。为了解决这些问题，Liu等人在2016年提出了SSD算法[ 8]，该算法利用多尺度特征图进行目标检测，可以有效地检测不同大小的目标，同时定位精度也有所提高。同年，Redmon等人提出了YOLOv2算法[ 9]，该算法替换了原有的骨干网络为DarkNet-19，提高了特征提取能力，从而在检测精度和速度上都有了一定提升。
2018年，Redmon等人又提出了YOLOv3算法[ 10]，该算法借鉴了FPN的思想进行多尺度的预测，同时采用了更深的骨干网络DarkNet-53，此骨干网络有效地提高了特征提取能力，能提取到更加细节的特征信息。最近，Glenn-jocher等人提出了YOLOv5算法，该算法在骨干网络中使用Focus 和CSP模块，以及在neck端使用FPN+PAN结构，同时在训练过程中使用了一些小策略来提升检测速度和精度。


图1 经典目标检测算法[3]
2.1 开放场景中的目标检测
传统目标检测方法在不同数据集上能够取得较高性能，取决于一个关键因素，即需要人工对相关数据集进行精致标注，这一工程耗时耗力。在开放场景中，由于目标类别繁杂，大部分需要检测的目标类别不包含在已经标注过的类别中，想要模型检测这些全新的类别对象时，需要增加新类别标注进行重新训练，如何避免昂贵标注实现对大量未知类别目标进行检测是一个极具挑战性的问题。
文献[1]围绕开放词汇目标检测展开，针对传统目标检测在开放场景中的局限性，探讨了如何利用语言和视觉的结合来扩展目标检测的能力，使其能够识别训练阶段未见的类别。主要方法包括：
1.基于大规模外部图像文本数据的方法：（a）区域-文本预训练，模型需要在图像－文本对数据上训练学习图像和文本对应关系，将学习到的对应关系迁移到检测器上进行微调适应下游检测任务；（b）伪标签文本对齐方法，能够有效提高模型对新类检测能力，大部分伪标签生成方法整体流程是两阶段的，即利用图像文本数据生成伪标签，用伪标签和目标检测数据集训练检测器。
2.基于预训练视觉语言模型：（a）知识蒸馏，将视觉知识直接蒸馏到闭集检测器中；（b）迁移学习，主要利用VLM图像编码器直接对检测数据进行微调，或通过冻结VLM图像编码器提取视觉特征用于下游检测任务；（c）提示学习，利用提示建模是一种有效的技术，通过将学习到的提示合并到基础模型中，可以使基础模型适应各种下游任务。
文献提到，基于以上方法的开放词汇检测模型仍存在问题，例如区域-文本预训练方式的预训练过程缓慢、基于VLM的方法中，知识蒸馏和迁移学习增加了模型计算量等。
未来开放词汇检测逐步完善，在纯图像检测之外应用开放词汇或许将成为主流趋势，关于开放词汇未来发展，有以下几个研究方向：更强的零样本泛化能力；轻量化检测模型；开放词汇视频分析；探索开放词汇3D场景理解；与人-物交互相结合；统一开放词汇检测与分割。

2.2 多模态的目标检测方法
目标检测任务不仅需要在算法层面学习图像中不同位置和尺度下目标的特征，还需要在应用层面适应光线变换、目标模糊等复杂场景。目前，传统的基于纯视觉的目标检测算法在处理单一场景时效果尚可，但在复杂设定中鲁棒性和泛化性有限。
文献[2]主要研究基于多模态学习的开放设定目标检测方法，创新地在视觉任务中引入文本模态，利用具有唯一性的文本嵌入指导目标检测任务中具体类别表征的学习。主要包括两个方面：1.构建多模态预训练模型，充分利用文本信息增强视觉特征表示；2.设计不同的算法框架，从应对实际开放设定场景出发，提升算法模型的鲁棒性和泛化性。
文章使用的目标检测模型框架为Faster R-CNN，主要由三个模块构成，分别是特征提取骨干网络、区域建议模块，最终分类定位模块，文章分章节分别提出问题并给出解决方案。
在第三章中，作者使用基于背景建模的领域泛化方法，提出了文本语义引导的视觉特征分类器，通过多模态表征对齐，减少假阳性和假阴性的情况，解决了完全不可知域的检测问题，提升了泛华能力；第四章，在研究如何减小源域和目标域数据之间的分布差异问题时，作者使用基于基础模型的领域自适应方法，构建视觉-语言预训练模型，增强类别粒度的表达能力，并提出了分层特征对齐策略，缓解领域分布差异引发的性能下降问题；第五章，作者基于字典学习的开放世界目标检测方法，构建实例字典，将标注类别与未标注类别联系起来，实现跨域和新类检测的集成，主要采用两阶段训练框架，缩小领域间的表征差距。第六章，为解决建立已知类与未知类之间的连接关系的问题，作者提出了一个大型开放海洋场景数据集MarineDet，用于研究海洋生物的新类检测，创新性地将陆地场景知识迁移至海洋场景，显著提升未标注类别检测的精度。
作者结合现有知识，认为以下方向仍然值得进一步研究：开放词汇目标检测、跨域目标检测、目标检测和目标分类领域中的长尾分布问题、针对小目标和遮挡目标的检测问题、背景建模难题、海洋生物多样性监测、算法模型轻量化等。

2.3 语音引导的目标检测方法
传统的目标检测任务为纯视觉任务，即输入为图像，没有其他模态信息作为输入。为将语言模态的信息融合到视觉任务中，通常采用两种技术路线，一种是提出一种新的模型结构，通过融合语言模态和视觉模态，最终输出有关目标检测的结果，这一技术路径可以表示为端到端的训练模式。第二条技术路径为基于预训练的“语言-视觉”模型，然后结合已有的目标检测算法模型结构来引入语言模态的信息。
对于端到端的技术路径，通常这些算法需要构建或使用图像-文本数据集，同时因为目标检测需要对图像区域进行定位，因此这类数据集往往包含区域级的描述以及对应的目标边界框。
基于预训练模型的方法，通常借助语言模型的能力来引入语言模态特征，并使用传统目标检测器，训练过程中通过建立视觉和语言特征的联系，最终达到提高目标检测模型能力的目的，训练后的模型要优于传统目标检测器，例如泛化能力更好或可以检测更多类别的目标。

图2 端到端语言引导目标检测部分方法[3]
文献[3]提出了一种基于视觉-语言模型CLIP微调的文本提示嵌入方法，用于无人机目标检测任务，通过语言引导去除领域特有特征。该方法将视觉特征投影到语言空间，并通过损失函数移除领域特有特征以提取域不变特征。
此外，利用可学习的域特有特征增强向量，增强了目标检测模型的特征泛化能力，使其能够克服多种领域特有特征。最后，还设计了一种基于语言的域特有特征增强方法(LFA)和基于语言的语义相似度损失函数(LSSL)，提高了目标检测模型在不同场景下泛化能力和分类精度。
在文章结尾，作者写出并未在通用目标检测任务和其他目标检测任务中做详细的算法验证，同时，在无人机目标检测任务上没有飞跃式的提升，说明在这个任务中仍然有较大的进步空间，并提出了几点改进策略：对齐-远离策略的改进、给予语言的域特有特征增强改进、基于语言的无人机目标检测算法的进一步研究。
无人机目标检测的难点是目标本身的信息量少，但有关目标的上下文信息多，可以对每个目标进行更加详细的，包含更多上下文的语言描述，例如对目标所处环境背景，周围目标等的描述，这样在训练过程中，算法可以显示的建立目标上下文和目标之间的关系，这将有利于弱小目标的检测。

2.4 面向小目标检测的算法研究
由于小尺度目标在所有目标中所占比例较小，自身的语义信息相对于大目标也较少，导致小目标检测的效果相对较差。如何提高小目标检测的精度是当前目标检测领域的一个难点。
针对小目标检测效果较差这一问题，文献[4]选用了YOLO系列最新推出的YOLOv8的轻量版本YOLOv 8s作为基线模型，通过改善其模型结构，以提升对小目标的检测能力，最后将优化后的模型在PASCASL VOC数据集上进行测试验证。其主要的研究内容包括改善特征图上检测点的感受野而在骨干网络加入的可变现卷积模块，加强小目标特征而在neck端加入的注意力机制，以及为了网络能够在不同阶段能自适应调整损失函数各部分的比例而设计的IoU准则。
YOLOv8算法由Glenn-Jocher提出，是跟YOLOv3算法、YOLOv5算法一脉相承的，在数据预处理、骨干网络结构、FPN-PAN结构、Detection head结构、标签分配策略方面做了较大改进。
在基于可变性卷积的目标检测方法研究中，作者将可变性卷积模块加入YOLO v8s的骨干网络中，可以提取到更多更细节的图像特征，从而为之后特征融合以及在检测头上做预测奠定基础。
在基于注意力机制的目标检测方法研究中，作者在YOLO v8s的neck端添加注意力模块，添加CBAM模块的位置是在PAN-FPN上采样阶段中的upsample结构后以及下采样阶段的每个C2f 模块后，在CBS模块卷积前，即在融合特征前都加入此模块。在优化后的模型中，融合特征前进行特征注意加强操作，模型可以更加注重小目标信息，增强对目标的关注，提升小目标的设定以及定位精度。
在基于改进IoU的目标检测方法研究中，作者自定义了一个HIoU算法，将传统的IoU中的交和并运算进行了改进，在动态调整边界框回归损失的同时削弱对距离、纵横比之类的几何度量的惩罚，这样做更好地考虑预测框和真实框之间的IoU、位置、大小、形状等多个因素，从而提高了目标检测的准确性。
在文章最后，作者阐述了自己后续的研究方向，一个是实现模型的轻量化处理，另一个是想要在三个检测头的基础上再添加一个辅助检测头，用来处理自然场景下的重复堆叠遮挡的情况。


3 大模型领域国内外研究现状
语言模型的发展历程大致可以分为四个阶段：统计语言模型(statistical language model, SLM)、神经网络语言模型(neural network language models,NNLM)、预训练语言模型(pre-trained language model,PLM)和大语言模型(large language model,LLM)。
统计语言模型(SLM)的起源和早期发展都与语音识别紧密相关[13]，它为语音识别系统提供了一种建模语言的方法，以改进自动语音识别的准确性。后来SLM 的概念扩展到自然语言处理的其他领域：机器翻译、文档分类和路由、光学字符识别、信息检索、手写识别、拼写纠正等等[13-14]。
神经网络语言模型(NLM)的起源是Bengio等人[15]提出的神经概率语言模型，但当时神经网络的作用仅限于简单地为已有的SLM提供单一特征[16]。直到2010年提出了基于RNN的语言模型，并证明其性能优于传统的N-gram模型，语言模型正式进入NLM阶段[17]。2013 年，Mikolov等人[18]又提出了词向量模型(Word2Vec)，将单词表示为分布式向量，并将分布式词表示的学习问题简化为一个监督学习问题，使用浅层神经网络来实现这一目标(而不是过去的词序列模型)，这种方法非常简洁、有效，Word2Vec也成为了自然语言处理中的一个重要里程碑。
预训练语言模型(PLM)的出现是由于研究者们希望将预先训练的语言表示应用于下游任务，在当时有两种策略：基于特征的方法和微调。基于特征的方法的代表是嵌入式语言模型(embeddings from language models, ELMo)[19]，使用双向LSTM模型来建模单词的复杂特征(语法、语义等)以及这些特征在上下文中的变化。Transformer结构的问世，促进了自然语言处理领域的发展[20]。BERT模型的成功宣告了PLM阶段正式开始，BERT使用大规模的未标记文本数据来预训练神经网络语言模型[21]。
大语言模型BERT、GPT1和GPT2等预训练模型的进步，奠定了大模型时代自然语言处理技术的基础。这些早期典型的PLM模型在特定的自然语言处理任务上表现出色，但是由于参数规模和处理能力的不足，这些模型在复杂文本结构的与上下文含义理解、语言细微差距的捕捉能力上还存在欠缺。除此之外，受限于全参数微调的原理，PLM模型在特定领域的微调训练时过度关注于训练数据，进而导致了泛化能力的不足，与较高的时间与计算资源成本。

图3 大模型的发展历程[12]
3.1 大语言模型在知识图谱领域的研究现状
尽管LLM具备很强的学习和创作等通用能力，但受限于其黑箱模型特性和领域知识缺乏等原因，其可解释性、可信赖性和领域能力都还难以令人满意[22]。而知识图谱凭借其结构化知识存储的特点，具有较好的可解释性、可溯源性、可信赖性和灵活性，恰好能够有效弥补LLM的这些不足[23]。
知识图谱构建主要包括实体抽取、关系抽取、实体链接等步骤。相比传统的知识图谱构建方法，PLM在上下文理解、零样本学习、多模态数据处理和迁移学习能力方面具有显著优势，且具有较强的领域和任务适应性。以下是基于PLM的知识图谱构建方法的相关信息：
（1）命名实体识别：a.非重叠NER，将命名实体视作一个整体，并将NER转化为序列标注问题来识别文本中不重叠的实体，未考虑一个标记属于多个实体的情况，使用的模型有BERT，biLM，DTPDR，P-Tuning v2；b.嵌套NER，考虑一个标记属于多个实体的情况，允许实体嵌套在其他实体之中并使用嵌套标签来表示，没有考虑实体被分隔的情况，使用的模型例如Biaffine，BENSC，PO-TreeCRFs等；c.非连接NER，识别在文本中以间隔分隔的实体，可以适应更多样化的实体表示，使用的方法有SoD-NER，D-NER。
（2）实体分类：a.基于标签对齐，应用于有监督场景，通过对齐模型中间或输出表示和目标任务的标签来进行微调，使用的模型有Denoise-ET，Box4Types，MLM-ET等；b.基于提示学习，通过提示学习来适应标签稀缺的无监督和少/零样本场景，使用的方法有OntoType等。
（3）实体对齐：利用PLM对GNN进行增强,或设计针对实体对齐的下游任务对PLM进行微调，使用的方法有BERT-INT，MAN and HMAN，TEA，ERNIE。
（4）关系抽取：a.基于MLM的句子级别RE，将关系抽取建模为掩码语言建模任务并进行微调来抽取句子内关系，更加可靠，但效率较低，例如TRE，SpanBERT，MTB等模型；b.基于MLM的文档级别RE，将关系抽取建模为掩码语言建模任务并进行微调，抽取文档内跨句子关系，通常采用分层建模、共现汇聚等方式实现，例如HIN，GLRE，GAIN等模型；c.基于提示学习，将关系抽取任务视为文本生成问题,在提示模板中引入输入句子, 利用模板中的附加信息辅助生成过程,更适用于少样本、零样本等受限场景，例如LPAQA，PTR等模型；d.实体知识增强，将实体编码到PLM中，增强PLM的语义和知识学习能力，提升关系抽取的性能，扩展性、灵活性强，其需要设计多任务联合训练策略和损失函数，训练成本高，且需要规模匹配的知识图谱，较为突出的如CokeBERT，Coref-BERT，ERICA等模型。
（5）实体链接：a.基于向量匹配，通过PLM或知识增强的PLM将实体编码为向量空间中的向量，然后计算匹配分数，计算复杂度高，所使用的有E-ELMo，BLINK，ELQ，E-BERT，FAE等模型；b.基于序列分析，将EL转化为序列分析问题，通过自回归等方式预测链接，不需要进行逐对遍历匹配，规避了学习大量实体嵌入表示的昂贵成本，例如GENRE and mGENRE，ReFinED等模型。
（6）端到端构建：a.文本-知识图谱，从文本中构建知识图谱，有代表的模型例如PiVe，KGLLM，AutoKG等；b.表格-知识图谱，从数据库、网络表格和CSV文件等表格数据中提取知识，例如TURL，RPT，Starmie等模型；c.模型-知识图谱，将模型存储的知识（参数形式）转化为知识图谱，例如COMET，BERTNet and RoBERTaNet等模型。
文献[12]指出，尽管基于PLM的知识图谱技术已经逐步发展完善，在多样化的知识图谱任务中表现出优异的性能，但由于知识图谱的语义和结构复杂性，以及PLM自身的缺陷，基于PLM 的知识图谱技术仍面临着很多亟待解决的问题。此外，随着 LLM的兴起，如何发挥其强大的生成和涌现能力来提升知识图谱技术的性能也是一个重要的研究方向。结合当前预训练语言模型和知识图谱的研究现状，基于预训练语言模型的知识图谱技术还存在如下7个方面的挑战：应对大模型幻觉、处理长尾实体、纠正语义偏差、结构化知识学习、评估模型推理性能、多种模态融合、知识动态更新等。
随着大模型时代的到来，部分研究者认为知识图谱的价值将减小。但是，科学研究范式的转变并不意味着知识图谱已经被淘汰，相反，对于那些关注可靠性、安全性和可解释性的研究领域，知识图谱这样的结构化知识依然是不可或缺的。知识图谱和LLM的融合，可以有效提升LLM的运行效率、知识实时性、可解释性、推理能力，进而实现深度认知，提升智能决策的速度和可信赖性。

3.2 大模型微调技术研究现状
随着自然语言处理技术的进步，对模型的处理能力、理解能力和生成能力的要求越来越高，与此同时，参数扩展法则指出，模型的规模和其性能之间存在正相关关系，通过增加模型的参数量，可以显著提高模型处理复杂任务的能力。但是由于预训练模型的参数量越来越大，需要调整的部分多，绝大部分的大语言模型的研究并没有采用传统全参数微调的方法[24],原因在于下游子任务的细化程度高，在微调的过程中需要调整大量参数，因而需要更多的计算资源，于是研究者们开始思考更为高效的微调方法。
经典的微调方法主要指全参数微调(full-parameter fine-tuning)，在效果上被认为是一种比高效参数微调更强大的方法[25]。在得到预训练模型后，为了使模型适应下游子任务，使用目标任务相契合的较少量特定任务数据继续训练模型。训练过程中，预训练模型的权重被更新，以便更好地适应具体的下游任务场景[26]。
全参数微调目前主要指监督微调，主要应用在下游子任务的模型迁移中，而无监督微调往往使用在模型的预训练阶段。无监督微调、自监督微调等在下游子任务上的微调应用还在发展阶段。有学者进一步考虑二者在微调中对模型中的归纳偏置(inductive biases)以及它们是否与训练集D或者任务集T的属性相关，而划分为行为微调(behavior fine-tuning)和自适应微调(adaptive fine-tuning)[27]。
在大语言模型的模型规模普及的背景下，对计算效率和资源使用的优化尤为重要。资源优化微调的目的在于减少微调时的资源消耗，例如通过只训练模型的一部分参数(如Transformer的最后几层)来实现。这种方法在尽可能保持性能的同时，减少了计算资源和时间的需求。在此背景下，一种优化参数量的微调训练方法被提出，高效参数微调(parameter-efficient fine-tuning, PEFT)得到了推广与发展。
相较于传统的全参数微调修改了所有的参数，研究人员探索发现了不同的高效参数方式。目前一种主流的观点将高效参数微调分为三类:增加式(addition-based)、 选取式(specification-based)和重参数化(reparameterization based)形式。这三种方法虽然思路上不尽相同，但结果都是通过少量的参数修改，达到基于下游子任务精细化微调的目的，并在参数为数十亿的大语言模型上能取得相对较好的效果。
文献[23]对大语言模型的微调技术，分析介绍了自大语言模型问世以来的多类微调方法，总结了其原理、发展与应用，并进行了相应的对比研究，得到的结果如表1所示。


4 总结
大型语言模型的崛起标志着深度学习领域的一次全新飞跃，成为了研究的前沿焦点。其背后的研究方向错综复杂，吸引了众多学者的关注与探索。目标检测是计算机视觉领域中重要的研究课题之一，在实现自动化、提高效率、推动科技发展方面具有广泛的研究和实际应用价值。二者虽然都属于人工智能和深度学习的研究领域，但它们的研究目标、方法和应用场景存在显著区别，同时也有一些交集。
在跨模态应用中，随着多模态模型的兴起，语言与视觉的结合成为了一个热门方向。例如图像描述生成、视觉问答（Visual Question Answering, VQA）等任务结合了语言模型与目标检测技术。在这些任务中，目标检测负责识别图像中的物体，而语言模型则负责理解图像描述或根据问题生成答案。
二者同样存在着模型架构的共性，在一些深度学习框架中，语言模型和目标检测模型都可以使用Transformer结构或类似的深度学习架构进行优化。比如，视觉-语言模型（如CLIP、BLIP等）通过将图像与语言共同嵌入到一个共享的特征空间中，实现跨模态的理解。
在数据驱动方面，两者都依赖于大规模的数据集进行训练，并通过深度神经网络从数据中提取特征。无论是语言数据还是图像数据，深度学习的成功都依赖于充足的训练数据和强大的计算能力。
同时，许多研究论文指出，模型轻量化仍是一个亟待解决的关键问题，而计算资源的优化利用和数据集的完善等方面也尚需进一步深入探讨。然而，值得注意的是，这些领域的研究竞争异常激烈，各个方向的论文数量每年都在不断攀升。因此，我认为多模态研究仍有巨大的潜力待挖掘，特别是在语音与图像的结合，在现有研究基础上，我们可以深入探讨并推动这一方向的发展。